fg = "white",
inches = FALSE, add = TRUE )
# 鼻子
symbols( cx+0, cy-0.5,
rectangles = matrix(c(0.5, 2), nrow =1),
fg = "white", bg = "white",
inches = FALSE, add = TRUE )
# 嘴巴
symbols( cx+0, cy-3.5,
squares = 1.5, fg = "white",
lwd = 2,
inches = FALSE, add = TRUE )
# 鬍子
polygon( c( cx-1.5, cx-2, cx-3), c( cy-2, cy-2, cy-3),
col = "white", border = "white" )
polygon( c( cx+1.5, cx+2, cx+3), c( cy-2, cy-2, cy-3),
col = "white", border = "white" )
}
# good way to animate the face
for ( i in 1:Num ){
myFace( x[i], y[i] )
#line <- readline()
Sys.sleep( 1 )
myFaceOff( x[i], y[i] )
#line <- readline()
}
x <- sin(1:90/45*pi)*15
y <- cos(1:90/45*pi)*15
plot( x, y,
xlim = c( -25, 25 ), ylim=c( -25, 25 )  )
# good way to animate the face
# good way to animate the face
for ( i in 1:Num ){
myFace( x[i], y[i] )
#line <- readline()
Sys.sleep( 0.1 )
myFaceOff( x[i], y[i] )
#line <- readline()
}
x <- c( -15:15, 15, 15:-15 )
y <- c( 1:15, 15, 15:1, 0, -1:-15, -15, -15:-1 )
plot( x, y,
xlim = c( -25, 25 ), ylim=c( -25, 25 )  )
# good way to animate the face
for ( i in 1:Num ){
myFace( x[i], y[i] )
#line <- readline()
Sys.sleep( 0.1 )
myFaceOff( x[i], y[i] )
#line <- readline()
}
x <- sample( -15:15, 20 )
y <- sample( -15:15, 20 )
plot( x, y,
xlim = c( -25, 25 ), ylim=c( -25, 25 )  )
# good way to animate the face
for ( i in 1:Num ){
myFace( x[i], y[i] )
#line <- readline()
Sys.sleep( 1 )
myFaceOff( x[i], y[i] )
#line <- readline()
}
mySort( 10:1, 1 )
mySort <- function( x, plottype ) {
itemCount <- length( x )
repeat {
hasChanged <- FALSE
itemCount <- itemCount - 1
if ( itemCount >= 1 ){
for( k in 1 : itemCount ) {
if ( x[ k ] > x[ k+1 ] ) {
t <- x[ k ]
x[ k ] <- x[ k+1 ]
x[ k+1 ] <- t
hasChanged <- TRUE
}
# print( c( k , x ) )
# bubble sort plot, vertical plot
if( plottype == 1 ){
plot( x, 1:length(x), pch = 1, cex = 8 )
text( x, 1:length(x), as.character( x ), col = "red", cex=2 )
}
# bubble sort plot, horizontal plot
if( plottype == 2 ){
plot( x, pch = 1, cex = 8  )
text( 1:length(x), x, as.character( x ), col = "red", cex=2 )
}
# some waiting time
Sys.sleep(0.5)
}
}
if ( !hasChanged ) break;
}
return( x )
}
mySort( 5:1, 1 )
mySort( datain, 1)
f <- function(x) 0.01 * x^3 * cos(x) - 0.2 * x^2 * sin(x) + 0.05 * x - 1
curve( f,
from = -10, to = 10 )
curve( f,
from = -10, to = 10,
n = 1001 )
curve( f,
from = -10, to = 10,
lty = 1, col = "red", ylab = "" )
curve( g,
add = TRUE,
lty = 2, col = "blue" )
legend( "topright",
legend = c("f", "g"),
lty = 1:2,
col = c("red", "blue"))
for ( i in 1:Num ){
myFace( x[i], y[i] )
#line <- readline()
Sys.sleep( 1 )
myFaceOff( x[i], y[i] )
#line <- readline()
}
# one way to animate the face
for ( i in 1:Num ){
Ball_0( x[i], y[i] )
Sys.sleep( 0.1 )  #停一秒鐘
}
plot( x, y,
xlim = c( -25, 25 ), ylim=c( -25, 25 )  )
Num <- length(x)   # 點的數量
# one way to animate the face
for ( i in 1:Num ){
Ball_0( x[i], y[i] )
Sys.sleep( 0.1 )  #停一秒鐘
}
install.packages('states')
library(states)
library(dplyr)
medianGdpPercap
library(gapminder)
install.packages(stats)
?medianGdpPercap
??medianGdpPercap
?summarize
summarize(iris)
summarize(car)
summarize(cars)
box_office <- c(new_hope,return_jedi,empire_strikes)
c(asdf,weweg,wgersdg)
source('pttTestFunction.R')
id = c(3000:3100)
URL = paste0("https://www.ptt.cc/bbs/Taoyuan/index", id, ".html")
filename = paste0(id, ".txt")
pttTestFunction(URL[1], filename[1])
source('pttTestFunction.R')
id = c(1:10)
URL = paste0("https://www.ptt.cc/bbs/Taoyuan/index", id, ".html")
filename = paste0(id, ".txt")
pttTestFunction(URL[1], filename[1])
mapply(pttTestFunction,
URL = URL, filename = filename)
source('pttTestFunction.R')
setwd("C:/Users/USER/Desktop/github/Week2")
source('pttTestFunction.R')
id = c(3000:3100)
URL = paste0("https://www.ptt.cc/bbs/Taoyuan/index", id, ".html")
filename = paste0(id, ".txt")
pttTestFunction(URL[1], filename[1])
mapply(pttTestFunction,
URL = URL, filename = filename)
id = c(100:200)
URL = paste0("https://www.ptt.cc/bbs/Taoyuan/index", id, ".html")
filename = paste0(id, ".txt")
pttTestFunction(URL[1], filename[1])
mapply(pttTestFunction,
URL = URL, filename = filename)
id = c(100:200)
URL = paste0("https://www.ptt.cc/bbs/Taoyuan/index", id, ".html")
filename = paste0(id, ".txt")
pttTestFunction(URL[1], filename[1])
#mapply(pttTestFunction,
#      URL = URL, filename = filename)
id = c(3800:3900)
URL = paste0("https://www.ptt.cc/bbs/Taoyuan/index", id, ".html")
filename = paste0(id, ".txt")
pttTestFunction(URL[1], filename[1])
#mapply(pttTestFunction,
#      URL = URL, filename = filename)
source('~/pttTestFunction.R')
source('pttTestFunction.R')
source('pttTestFunction.R')
id = c(3100:3200)
URL = paste0("https://www.ptt.cc/bbs/Taoyuan/index", id, ".html")
filename = paste0(id, ".txt")
pttTestFunction(URL[1], filename[1])
#mapply(pttTestFunction,
#      URL = URL, filename = filename)
rm(list=ls(all.names = TRUE))
library(NLP)
library(tm)
library(jiebaRD)
library(jiebaR)
library(RColorBrewer)
library(wordcloud)
filenames <- list.files(getwd(), pattern="*.txt")
files <- lapply(filenames, readLines)
docs <- Corpus(VectorSource(files))
#移除可能有問題的符號
toSpace <- content_transformer(function(x, pattern) {
return (gsub(pattern, " ", x))
}
)
docs <- tm_map(docs, toSpace, "※")
docs <- tm_map(docs, toSpace, "◆")
docs <- tm_map(docs, toSpace, "‧")
docs <- tm_map(docs, toSpace, "的")
docs <- tm_map(docs, toSpace, "我")
docs <- tm_map(docs, toSpace, "是")
docs <- tm_map(docs, toSpace, "看板")
docs <- tm_map(docs, toSpace, "作者")
docs <- tm_map(docs, toSpace, "發信站")
docs <- tm_map(docs, toSpace, "批踢踢實業坊")
docs <- tm_map(docs, toSpace, "[a-zA-Z]")
#移除標點符號 (punctuation)
#移除數字 (digits)、空白 (white space)
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, stripWhitespace)
docs
mixseg = worker()
jieba_tokenizer=function(d){
unlist(segment(d[[1]],mixseg))
}
seg = lapply(docs, jieba_tokenizer)
freqFrame = as.data.frame(table(unlist(seg)))
freqFrame = freqFrame[order(freqFrame$Freq,decreasing=TRUE), ]
library(knitr)
kable(head(freqFrame), format = "markdown")
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
source('pttTestFunction.R')
id = c(3100:3200)
URL = paste0("https://www.ptt.cc/bbs/Hsinchu/index", id, ".html")
filename = paste0(id, ".txt")
pttTestFunction(URL[1], filename[1])
#mapply(pttTestFunction,
#      URL = URL, filename = filename)
source('pttTestFunction.R')
id = c(3100:3200)
URL = paste0("https://www.ptt.cc/bbs/Taipei/index", id, ".html")
filename = paste0(id, ".txt")
pttTestFunction(URL[1], filename[1])
#mapply(pttTestFunction,
#      URL = URL, filename = filename)
source('pttTestFunction.R')
id = c(3100:3200)
URL = paste0("https://www.ptt.cc/bbs/Taipei/index", id, ".html")
filename = paste0(id, ".txt")
pttTestFunction(URL[1], filename[1])
#mapply(pttTestFunction,
#      URL = URL, filename = filename)
source('pttTestFunction.R')
id = c(3100:3200)
URL = paste0("https://www.ptt.cc/bbs/Taipei/index", id, ".html")
filename = paste0(id, ".txt")
pttTestFunction(URL[1], filename[1])
mapply(pttTestFunction,
URL = URL, filename = filename)
id = c(300:350)
URL = paste0("https://www.ptt.cc/bbs/Taipei/index", id, ".html")
filename = paste0(id, ".txt")
pttTestFunction(URL[1], filename[1])
mapply(pttTestFunction,
URL = URL, filename = filename)
rm(list=ls(all.names = TRUE))
library(NLP)
library(tm)
library(jiebaRD)
library(jiebaR)
library(RColorBrewer)
library(wordcloud)
filenames <- list.files(getwd(), pattern="*.txt")
files <- lapply(filenames, readLines)
docs <- Corpus(VectorSource(files))
#移除可能有問題的符號
toSpace <- content_transformer(function(x, pattern) {
return (gsub(pattern, " ", x))
}
)
docs <- tm_map(docs, toSpace, "※")
docs <- tm_map(docs, toSpace, "◆")
docs <- tm_map(docs, toSpace, "‧")
docs <- tm_map(docs, toSpace, "的")
docs <- tm_map(docs, toSpace, "我")
docs <- tm_map(docs, toSpace, "是")
docs <- tm_map(docs, toSpace, "看板")
docs <- tm_map(docs, toSpace, "作者")
docs <- tm_map(docs, toSpace, "發信站")
docs <- tm_map(docs, toSpace, "批踢踢實業坊")
docs <- tm_map(docs, toSpace, "[a-zA-Z]")
#移除標點符號 (punctuation)
#移除數字 (digits)、空白 (white space)
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, stripWhitespace)
docs
source('pttTestFunction.R')
id = c(1000:1100)
URL = paste0("https://www.ptt.cc/bbs/Taipei/index", id, ".html")
filename = paste0(id, ".txt")
pttTestFunction(URL[1], filename[1])
mapply(pttTestFunction,
URL = URL, filename = filename)
source('pttTestFunction.R')
id = c(1000:1003)
URL = paste0("https://www.ptt.cc/bbs/Taipei/index", id, ".html")
filename = paste0(id, ".txt")
pttTestFunction(URL[1], filename[1])
mapply(pttTestFunction,
URL = URL, filename = filename)
rm(list=ls(all.names = TRUE))
library(NLP)
library(tm)
library(jiebaRD)
library(jiebaR)
library(RColorBrewer)
library(wordcloud)
filenames <- list.files(getwd(), pattern="*.txt")
files <- lapply(filenames, readLines)
docs <- Corpus(VectorSource(files))
#移除可能有問題的符號
toSpace <- content_transformer(function(x, pattern) {
return (gsub(pattern, " ", x))
}
)
docs <- tm_map(docs, toSpace, "※")
docs <- tm_map(docs, toSpace, "◆")
docs <- tm_map(docs, toSpace, "‧")
docs <- tm_map(docs, toSpace, "的")
docs <- tm_map(docs, toSpace, "我")
docs <- tm_map(docs, toSpace, "是")
docs <- tm_map(docs, toSpace, "看板")
docs <- tm_map(docs, toSpace, "作者")
docs <- tm_map(docs, toSpace, "發信站")
docs <- tm_map(docs, toSpace, "批踢踢實業坊")
docs <- tm_map(docs, toSpace, "[a-zA-Z]")
#移除標點符號 (punctuation)
#移除數字 (digits)、空白 (white space)
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, stripWhitespace)
docs
mixseg = worker()
jieba_tokenizer=function(d){
unlist(segment(d[[1]],mixseg))
}
seg = lapply(docs, jieba_tokenizer)
freqFrame = as.data.frame(table(unlist(seg)))
freqFrame = freqFrame[order(freqFrame$Freq,decreasing=TRUE), ]
library(knitr)
kable(head(freqFrame), format = "markdown")
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
source('pttTestFunction.R')
id = c(1000:1003)
URL = paste0("https://www.ptt.cc/bbs/Taipei/index", id, ".html")
filename = paste0(id, ".txt")
pttTestFunction(URL[1], filename[1])
mapply(pttTestFunction,
URL = URL, filename = filename)
mixseg = worker()
jieba_tokenizer=function(d){
unlist(segment(d[[1]],mixseg))
}
seg = lapply(docs, jieba_tokenizer)
freqFrame = as.data.frame(table(unlist(seg)))
freqFrame = freqFrame[order(freqFrame$Freq,decreasing=TRUE), ]
library(knitr)
kable(head(freqFrame), format = "markdown")
rm(list=ls(all.names = TRUE))
library(NLP)
library(tm)
library(jiebaRD)
library(jiebaR)
library(RColorBrewer)
library(wordcloud)
filenames <- list.files(getwd(), pattern="*.txt")
files <- lapply(filenames, readLines)
docs <- Corpus(VectorSource(files))
toSpace <- content_transformer(function(x, pattern) {
return (gsub(pattern, " ", x))
}
)
docs <- tm_map(docs, toSpace, "※")
docs <- tm_map(docs, toSpace, "◆")
docs <- tm_map(docs, toSpace, "‧")
docs <- tm_map(docs, toSpace, "的")
docs <- tm_map(docs, toSpace, "我")
docs <- tm_map(docs, toSpace, "是")
docs <- tm_map(docs, toSpace, "看板")
docs <- tm_map(docs, toSpace, "作者")
docs <- tm_map(docs, toSpace, "發信站")
docs <- tm_map(docs, toSpace, "批踢踢實業坊")
docs <- tm_map(docs, toSpace, "[a-zA-Z]")
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, stripWhitespace)
docs
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
rm(list=ls(all.names = TRUE))
library(NLP)
library(tm)
library(jiebaRD)
library(jiebaR)
library(RColorBrewer)
library(wordcloud)
filenames <- list.files(getwd(), pattern="*.txt")
files <- lapply(filenames, readLines)
docs <- Corpus(VectorSource(files))
#移除可能有問題的符號
toSpace <- content_transformer(function(x, pattern) {
return (gsub(pattern, " ", x))
}
)
docs <- tm_map(docs, toSpace, "※")
docs <- tm_map(docs, toSpace, "◆")
docs <- tm_map(docs, toSpace, "‧")
docs <- tm_map(docs, toSpace, "的")
docs <- tm_map(docs, toSpace, "我")
docs <- tm_map(docs, toSpace, "是")
docs <- tm_map(docs, toSpace, "看板")
docs <- tm_map(docs, toSpace, "作者")
docs <- tm_map(docs, toSpace, "發信站")
docs <- tm_map(docs, toSpace, "批踢踢實業坊")
docs <- tm_map(docs, toSpace, "[a-zA-Z]")
#移除標點符號 (punctuation)
#移除數字 (digits)、空白 (white space)
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, stripWhitespace)
docs
mixseg = worker()
jieba_tokenizer=function(d){
unlist(segment(d[[1]],mixseg))
}
seg = lapply(docs, jieba_tokenizer)
freqFrame = as.data.frame(table(unlist(seg)))
freqFrame = freqFrame[order(freqFrame$Freq,decreasing=TRUE), ]
library(knitr)
kable(head(freqFrame), format = "markdown")
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
rm(list=ls(all.names = TRUE))
library(NLP)
library(tm)
library(jiebaRD)
library(jiebaR)
library(RColorBrewer)
library(wordcloud)
filenames <- list.files(getwd(), pattern="*.txt")
files <- lapply(filenames, readLines)
docs <- Corpus(VectorSource(files))
toSpace <- content_transformer(function(x, pattern) {
return (gsub(pattern, " ", x))
}
)
docs <- tm_map(docs, toSpace, "※")
docs <- tm_map(docs, toSpace, "◆")
docs <- tm_map(docs, toSpace, "‧")
docs <- tm_map(docs, toSpace, "的")
docs <- tm_map(docs, toSpace, "我")
docs <- tm_map(docs, toSpace, "是")
docs <- tm_map(docs, toSpace, "看板")
docs <- tm_map(docs, toSpace, "作者")
docs <- tm_map(docs, toSpace, "發信站")
docs <- tm_map(docs, toSpace, "批踢踢實業坊")
docs <- tm_map(docs, toSpace, "[a-zA-Z]")
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, stripWhitespace)
docs
mixseg = worker()
jieba_tokenizer=function(d){
unlist(segment(d[[1]],mixseg))
}
seg = lapply(docs, jieba_tokenizer)
freqFrame = as.data.frame(table(unlist(seg)))
freqFrame = freqFrame[order(freqFrame$Freq,decreasing=TRUE), ]
library(knitr)
kable(head(freqFrame), format = "markdown")
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
